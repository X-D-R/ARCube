{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ffc4bc1-bd32-4f89-98b6-d573e1129059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd079b7-4c61-4d3c-861a-772a937f90f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img1 = cv.imread('./detect/book.jpg', cv.IMREAD_GRAYSCALE)\n",
    "print(type(img1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5b8fd2-931e-43cf-9a4f-66320915a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "MIN_MATCH_COUNT = 10\n",
    " \n",
    "img1 = cv.imread('./detect/book.jpg', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "img2 = cv.imread('./detect/book_on_table.jpg', cv.IMREAD_GRAYSCALE) # trainImage\n",
    " \n",
    "# Initiate SIFT detector\n",
    "sift = cv.SIFT_create()\n",
    " \n",
    "# find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "kp2, des2 = sift.detectAndCompute(img2,None)\n",
    " \n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    " \n",
    "flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    " \n",
    "matches = flann.knnMatch(des1,des2,k=2)\n",
    " \n",
    "# store all the good matches as per Lowe's ratio test.\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        good.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2ac572-45fb-44f6-b314-00febdf840ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(kp1), type(des1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b771bf-2d13-4889-ae9d-bd6fdffc9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(good)>MIN_MATCH_COUNT:\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    " \n",
    "    M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "    matchesMask = mask.ravel().tolist()\n",
    " \n",
    "    h,w = img1.shape\n",
    "    pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    " \n",
    "    img2 = cv.polylines(img2,[np.int32(dst)],True,255,3, cv.LINE_AA)\n",
    " \n",
    "else:\n",
    "    print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "    matchesMask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db905c5-2f47-40f6-a7a1-367cbaec2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "                   singlePointColor = None,\n",
    "                   matchesMask = matchesMask, # draw only inliers\n",
    "                   flags = 2)\n",
    " \n",
    "img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    " \n",
    "plt.imshow(img3, 'gray'),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c60065-cbe4-4c29-8080-a5d81621cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"./detect/tea_video.mp4\")\n",
    "backSub = cv.createBackgroundSubtractorMOG2()\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    #print(ret, frame)\n",
    "    if ret:\n",
    "        # Apply background subtraction\n",
    "        fg_mask = backSub.apply(frame)\n",
    "contours, hierarchy = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# print(contours)\n",
    "frame_ct = cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)\n",
    "# Display the resulting frame\n",
    "cv2.imshow('Frame_final', frame_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967cc44-9667-4969-9102-756189f2d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd997603-1275-4257-a00b-ebf2561a05b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('CameraParams.npz') as file:\n",
    "    mtx, dist, rvecs, tvecs = [file[i] for i in ('cameraMatrix', 'dist', 'rvecs', 'tvecs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fb07d-c783-4f78-99e1-1c54c5c326d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('./detect/book.jpg')\n",
    "print(images)\n",
    "ind = 0\n",
    "for fname in images:\n",
    "\n",
    "    ind += 1\n",
    "    img = cv.imread(fname)\n",
    "    h, w = img.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    # undistort\n",
    "    dst = cv.undistort(img, mtx, dist, None, newcameramtx)\n",
    " \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    dst = dst[y:y+h, x:x+w]\n",
    "    cv.imwrite('./detect/book_'+str(ind)+'.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45381f-75b9-432f-be6a-aa49c99ddfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(\"./detect/tea_video.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "ind = 0\n",
    "while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    h, w = frame.shape[:2]\n",
    "    newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    # undistort\n",
    "    dst = cv.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "    cv.imwrite('./videoframes_tea/frame_'+str(ind)+'.png', frame)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd39d66-dddc-46dd-95cd-a8f15a4c9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "MIN_MATCH_COUNT = 10\n",
    " \n",
    "img1 = cv.imread('./detect/new_book.jpg', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "sift = cv.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "\n",
    "\n",
    "def findMatch(fname, out):\n",
    "    global kp1, des1;\n",
    "    imgS = cv.imread(fname) # trainImage\n",
    "    img2 = cv.cvtColor(imgS, cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.SIFT_create()\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    " \n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    " \n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    " \n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        #drawCountour(img, M)\n",
    " \n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)\n",
    "        pts = np.float32([ [123,1146],[2772,2175],[3484,720],[1209,263]]).reshape(-1,1,2)\n",
    "        pts2 = np.float32([[207,1402],[2748,2465],[3455,983],[1267,485]]).reshape(-1,1,2)\n",
    "        pts3 = np.float32([[123,1146],[207,1402],[2748,2465],[2772,2175],[3484,720],[3455,983],[1267,485],[1209,263]]).reshape(-1,1,2)\n",
    "        #pts = np.float32([ [133,1159],[2769, 2176],[3487, 718],[1214,264], [133,1159], [266,1410], [2734,2425],[3397,1029], [1347,515], [266,1410], [1347,515], [1214,264],[3487, 718],[3397,1029], [2734,2425],[2769, 2176]]).reshape(-1,1,2)\n",
    "        dst = cv.perspectiveTransform(pts,M)\n",
    "        dst2 = cv.perspectiveTransform(pts2,M)\n",
    "        dst3 = cv.perspectiveTransform(pts3,M)\n",
    "        img2 = cv.polylines(imgS,[np.int32(dst)],True, (0, 255, 0), 5)\n",
    "        img2 = cv.polylines(img2,[np.int32(dst2)],True, (0, 255, 0), 5)\n",
    "        img2 = cv.polylines(img2,[np.int32(dst3)],True, (0, 255, 0), 5)\n",
    "        for i, m in enumerate(good):\n",
    "            pt = (int(dst_pts[i][0][0]), int(dst_pts[i][0][1]))\n",
    "            if matchesMask[i]:\n",
    "                cv.circle(img2, pt, 5, (0, 255, 255), -1)  # Inliers желтые\n",
    "            else:\n",
    "                cv.circle(img2, pt, 5, (0, 0, 255), -1)    # Outliers красные\n",
    " \n",
    "    else:\n",
    "        print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        matchesMask = None\n",
    "    \n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "    singlePointColor = None,\n",
    "    matchesMask = matchesMask, # draw only inliers\n",
    "    flags = 2)\n",
    "    #img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "    #plt.imshow(img3),plt.show()\n",
    "    #img3 = cv.drawKeypoints(img2, [kp2[m.trainIdx] for m in good], cv.DRAW_MATCHES_FLAGS_DEFAULT, color=(0, 255, 255))\n",
    "\n",
    "    #plt.imshow(img2),plt.show()\n",
    "    out.write(img2)\n",
    "    cv.imwrite('./videoframes_rotate_detected/frame_'+str(ind)+'.png', img2)\n",
    "    plt.imshow(img2),plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad6e3d-8a97-4115-a08f-fdcfe707344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(points_r, rvecs, tvec, cam_m, dist):\n",
    "    p_2d = []\n",
    "    for i in range(len(points_r)):\n",
    "        x = points_r[i][0]\n",
    "        y = points_r[i][1]\n",
    "        z = points_r[i][2]\n",
    "        p_t = np.zeros(3)\n",
    "        p_t[0] = rvecs[0][0]*x + rvecs[0][1]*y + rvecs[0][2]*z + tvec[0]\n",
    "        p_t[1] = rvecs[1][0]*x + rvecs[1][1]*y + rvecs[1][2]*z + tvec[1]\n",
    "        p_t[2] = rvecs[2][0]*x + rvecs[2][1]*y + rvecs[2][2]*z + tvec[2]\n",
    "        x_ = p_t[0]/p_t[2]\n",
    "        y_ = p_t[1]/p_t[2]\n",
    "        r_2 = (x_)**2 + (y_)**2\n",
    "        x_d = x_ * (1 + dist[0]*r_2 + dist[1]*(r_2)**2 + dist[2]*(r_2)**3)/(1 + dist[3]*r_2 + dist[3]*(r_2)**2)\n",
    "        y_d = y_ * (1 + dist[0]*r_2 + dist[1]*(r_2)**2 + dist[2]*(r_2)**3)/(1 + dist[3]*r_2 + dist[3]*(r_2)**2)\n",
    "        u = cam_m[0][0]*x_d + cam_m[0][2]\n",
    "        v = cam_m[1][1] * y_d + cam_m[1][2]\n",
    "        p_2d.append([u, v])\n",
    "        \n",
    "    return np.array(p_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a4dcc-b773-44dc-be3d-1890b98ac0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(points_r, rvecs, tvec, cam_m, dist):\n",
    "    p_2d = np.zeros((len(points_r), 2))\n",
    "    dist = np.pad(dist[0], (0, 6 - len(dist[0])), 'constant', constant_values=0)\n",
    "    for i in range(len(points_r)):\n",
    "        p_t = (rvecs @ points_r[i] + tvec.T)[0]\n",
    "        x_ = p_t[0]/p_t[2]\n",
    "        y_ = p_t[1]/p_t[2]\n",
    "        r_2 = np.power(x_, 2) + np.power(y_, 2)\n",
    "        coeff =  (1 + dist[0]*r_2 + dist[1]*np.power(r_2, 2) + dist[2]*np.power(r_2, 3))/(1 + dist[3]*r_2 + dist[4]*np.power(r_2, 2) + dist[5]*np.power(r_2, 3))\n",
    "        u = cam_m[0][0] * x_ * coeff + cam_m[0][2]\n",
    "        v = cam_m[1][1] * y_ * coeff + cam_m[1][2]\n",
    "        p_2d[i][0] = u\n",
    "        p_2d[i][1] = v\n",
    "        \n",
    "    return p_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3ff56-adef-4859-b0b2-736317079413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "MIN_MATCH_COUNT = 10\n",
    "Z_LENGTH = 881.77\n",
    " \n",
    "img1 = cv.imread('./detect/tea.jpg', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "sift = cv.SIFT_create()\n",
    "kp1, des1 = sift.detectAndCompute(img1,None)\n",
    "\n",
    "\n",
    "def findMatch(fname, out):\n",
    "    global kp1, des1;\n",
    "    imgS = cv.imread(fname) # trainImage\n",
    "    if imgS is None:\n",
    "        return False\n",
    "    img2 = cv.cvtColor(imgS, cv.COLOR_BGR2GRAY)\n",
    "    sift = cv.SIFT_create()\n",
    "    kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    " \n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    " \n",
    "    # store all the good matches as per Lowe's ratio test.\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        with np.load('CameraParams.npz') as file:\n",
    "            mtx, dist, _, _ = [file[i] for i in ('cameraMatrix', 'dist', 'rvecs', 'tvecs')]\n",
    " \n",
    "        M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel().tolist()\n",
    "        #drawCountour(img, M)\n",
    " \n",
    "        h,w = img1.shape\n",
    "        pts = np.float32([ [0,0],[w-1,0], [w-1,h-1],[0,h-1], [w-1, w-1],[0, w-1]]).reshape(-1,1,2)\n",
    "        dst = cv.perspectiveTransform(pts,M)\n",
    "        img2 = cv.polylines(imgS,[np.int32(dst[:4, :, :])],True, (0, 255, 255), 6)\n",
    "        h2, w2 = img2.shape[:2]\n",
    "        #dist2 = np.zeros(4)\n",
    "        newcameramtx, roi = cv.getOptimalNewCameraMatrix(mtx, dist, (w2,h2), 1, (w2,h2))\n",
    "        objPoints = np.array([[0., 0., 0.], [w-1, 0., 0.], [w-1, w-1, 0.], [0., w-1, 0.]])\n",
    "        valid, rvec, tvec = cv.solvePnP(objPoints, dst[[True, True, False, False, True, True]], newcameramtx, dist, cv.SOLVEPNP_P3P)\n",
    "        #cv.drawFrameAxes(img2, newcameramtx, dist, rvec, tvec, 10000)\n",
    "        rvecs = cv.Rodrigues(rvec)[0]\n",
    "        objPoints = np.array([[0., 0., 0.], [0., 0., Z_LENGTH-1],[w-1, 0., 0.], [w-1, 0., Z_LENGTH-1],[w-1, h-1, 0.], [w-1, h-1, Z_LENGTH-1],\n",
    "                              [0., h-1, 0.], [0., h-1, Z_LENGTH-1]])\n",
    "        rvecs = cv.Rodrigues(rvec)[0]\n",
    "        d2 = trans(objPoints, rvecs, tvec, newcameramtx, dist)\n",
    "        #img2 = cv.polylines(imgS,[np.int32(d2)],True, (0, 0, 255), 2)\n",
    "        diff_z = np.array(d2[1::2] - d2[::2])\n",
    "        new_dst = dst[:4, :, :] + diff_z.reshape(-1,1,2)\n",
    "        img2 = cv.polylines(img2,[np.int32(new_dst)],True, (0, 255, 255), 6)\n",
    "        col_dst = [dst[0], new_dst[0], new_dst[1], dst[1], dst[2], new_dst[2], new_dst[3], dst[3]]\n",
    "        img2 = cv.polylines(img2,[np.int32(col_dst)],True, (0, 255, 255), 6)\n",
    "        for i, m in enumerate(good):\n",
    "            pt = (int(dst_pts[i][0][0]), int(dst_pts[i][0][1]))\n",
    "            if matchesMask[i]:\n",
    "                cv.circle(img2, pt, 5, (0, 255, 255), -1)  # Inliers желтые\n",
    "            else:\n",
    "                cv.circle(img2, pt, 5, (0, 0, 255), -1)    # Outliers красные\n",
    " \n",
    "    else:\n",
    "        print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "        matchesMask = None\n",
    "    \n",
    "    draw_params = dict(matchColor = (0,255,0), # draw matches in green color\n",
    "    singlePointColor = None,\n",
    "    matchesMask = matchesMask, # draw only inliers\n",
    "    flags = 2)\n",
    "    #img3 = cv.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)\n",
    "    #plt.imshow(img3),plt.show()\n",
    "    #img3 = cv.drawKeypoints(img2, [kp2[m.trainIdx] for m in good], cv.DRAW_MATCHES_FLAGS_DEFAULT, color=(0, 255, 255))\n",
    "\n",
    "    #plt.imshow(img2),plt.show()\n",
    "    out.write(img2)\n",
    "    cv.imwrite('./videoframes_tea_detected/frame_'+str(ind)+'.png', img2)\n",
    "    plt.imshow(img2),plt.show()\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf84f0af-6b4e-4d62-8d94-7e442522abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "ind = 0\n",
    "img = cv.imread('./videoframes_tea/frame_0.png')\n",
    "height, width, channels = img.shape\n",
    "out = cv.VideoWriter('output_tea.mp4', 0, 30.0, (width, height))\n",
    "while True:\n",
    "    ret = findMatch('./videoframes_tea/frame_'+str(ind)+'.png', out)\n",
    "    if not ret:\n",
    "        break\n",
    "    ind += 1\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66509bc2-a592-41a8-8f2f-4381a5525623",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0d7d8c-faa7-46f7-85f8-a14b8c7ad2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('./detect/book.jpg', cv.IMREAD_GRAYSCALE)          # queryImage\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "print(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50073657-4261-434d-9a8f-9827c46339a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "ind = 0\n",
    "img = cv.imread('./videoframes_tea/frame_0.png')\n",
    "height, width, channels = img.shape \n",
    "out = cv.VideoWriter('output.mp4', 0, 30.0, (width, height))\n",
    "findMatch('./videoframes_tea/frame_500.png', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ca00e-7e09-4593-b9a4-4a1e403bba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawCountour(img, M):\n",
    "    h,w = img1.shape\n",
    "    d = 442\n",
    "    pts = np.float32([ [0,0,0],[0,h-1,0],[w-1,h-1,0],[w-1,0,0], [0,0,442],[0,h-1,442],[w-1,h-1,442],[w-1,0,442]]).reshape(-1,1,2)\n",
    "    dst = cv.perspectiveTransform(pts,M)\n",
    "    print(dst)\n",
    "    img2 = cv.polylines(img,[np.int32(dst)],True, (0, 255, 0), 5)\n",
    "    for i, m in enumerate(good):\n",
    "        pt = (int(dst_pts[i][0][0]), int(dst_pts[i][0][1]))\n",
    "        if matchesMask[i]:\n",
    "            cv.circle(img2, pt, 5, (0, 255, 255), -1)  # Inliers желтые\n",
    "        else:\n",
    "            cv.circle(img2, pt, 5, (0, 0, 255), -1)    # Outliers красные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49e3de-ceaf-46e1-abfd-c34b7fe8475e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e98e7-338d-4cf4-adc9-6765b63f1b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
